---
title: "HW1_Statistical Machine Learning"
author: "Moran Guo"
date: "2024-08-27"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Question 1 (3.7-5)**

We have $\displaystyle \hat{y}_i = x_i \hat{\beta} = x_i \Big(\frac{\sum_{i'=1}^nx_{i'}y_{i'}}{\sum_{j = 1}^n x_j^2}\Big)$ so that $\displaystyle \hat{y}_i = \sum_{i'=1}^n \Big(\frac{x_i x_{i'}}{\sum_{j=1}^n x_j^2}\Big)y_i'$, therefore $$a_i' = \frac{x_ix_i'}{\sum_{j=1}^n x_j^2}.$$

**Question 2 (3.7-6)**

We have the least-square linear regression as $\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x$, we plug in $x = \bar{x}$ and $\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$ then we have $$\hat{y} = \bar{y} - \hat{\beta}_1 \bar{x} + \hat{\beta}_1 \bar{x} = \bar{y}.$$

Therefore, the point $(\bar{x}, \bar{y})$ must be on the least-square line.

**Question 3 (3.7-9)**

```{r auto scatterplot}
# (a) Scatterplot Matrix
# install.packages("ISLR")
library(ISLR)
data(Auto)
plot(Auto, cex = 0.4, col = "lightblue")
```

```{r correlation}
# (b) correlation matrix
cor(Auto[, 1:8]) # Excluded the first variable 'name'
```

```{r multiple linear regression}
# (c) multiple linear regression
car_lm_fit <- lm(mpg ~ . - name, data = Auto)
summary(car_lm_fit)
```

(i) From the result, we see a significant *p*-value and a sufficiently large F statistics for the overall model fit, which suggests that there exist a linear relationship between mpg and other predictors.

(ii)
