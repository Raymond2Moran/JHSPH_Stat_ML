---
title: "HW1_Statistical Machine Learning"
author: "Moran Guo"
date: "2024-08-27"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Question 1 (3.7-5)**

We have $\displaystyle \hat{y}_i = x_i \hat{\beta} = x_i \Big(\frac{\sum_{i'=1}^nx_{i'}y_{i'}}{\sum_{j = 1}^n x_j^2}\Big)$ so that $\displaystyle \hat{y}_i = \sum_{i'=1}^n \Big(\frac{x_i x_{i'}}{\sum_{j=1}^n x_j^2}\Big)y_i'$, therefore $$a_i' = \frac{x_ix_i'}{\sum_{j=1}^n x_j^2}.$$

**Question 2 (3.7-6)**

We have the least-square linear regression as $\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x$, we plug in $x = \bar{x}$ and $\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$ then we have $$\hat{y} = \bar{y} - \hat{\beta}_1 \bar{x} + \hat{\beta}_1 \bar{x} = \bar{y}.$$

Therefore, the point $(\bar{x}, \bar{y})$ must be on the least-square line.

**Question 3 (3.7-9)**

```{r auto}
# install.packages("ISLR")
library(ISLR)
data(Auto)
plot(Auto, cex = 0.4, col = "lightblue")
```
